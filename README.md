# mlp-activation-analysis_23098873
A comparative study of activation functions (ReLU, Swish, Tanh, Sigmoid) in a 3-layer Multilayer Perceptron (MLP) trained on Fashion-MNIST. Includes PyTorch code, training curves, and reproducibility instructions.
